{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A RAG pipeline using tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from unstructured.partition.html import partition_html\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial was inspired by https://docs.llamaindex.ai/en/latest/examples/query_engine/sec_tables/tesla_10q_table.html#perform-data-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_URL = \"https://www.segurossura.com.co/documentos/condicionados/personas/vehiculos/plan-autos-global-clasico-basico.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "# TODO: Explain what this is\n",
    "class Element(BaseModel):\n",
    "    id: str\n",
    "    type: str\n",
    "    element: Any\n",
    "    summary: str | None = None\n",
    "    table: pd.DataFrame | None = None\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://www.dropbox.com/scl/fi/mlaymdy1ni1ovyeykhhuk/tesla_2021_10k.htm?rlkey=qf9k4zn0ejrbm716j0gg7r802&dl=1\" -O tesla_2021_10k.htm\n",
    "# !wget \"https://www.dropbox.com/scl/fi/rkw0u959yb4w8vlzz76sa/tesla_2020_10k.htm?rlkey=tfkdshswpoupav5tqigwz1mp7&dl=1\" -O tesla_2020_10k.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "\n",
    "def html_to_df(html_str: str) -> pd.DataFrame:\n",
    "    # print(html_str)\n",
    "    tree = html.fromstring(html_str)\n",
    "    # print(tree.xpath('//table'))\n",
    "    table_element = tree.xpath(\"//table\")[0]\n",
    "    rows = table_element.xpath(\".//tr\")\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.xpath(\".//td\")\n",
    "        cols = [c.text.strip() if c.text is not None else \"\" for c in cols]\n",
    "        data.append(cols)\n",
    "\n",
    "    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_table(table_element):\n",
    "    table_df = html_to_df(table_element.metadata.text_as_html)\n",
    "    if len(table_df) <= 1 or len(table_df.columns) <= 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts elements from HTML. If table and meets filter conditions, store as Pydantic table element\n",
    "# otherwise, store as text. Discard if table but does not pass filters.\n",
    "def extract_elements(filename, table_filters=[]):\n",
    "    elements = partition_html(filename=filename)\n",
    "    output_els = []\n",
    "    for idx, element in enumerate(elements):\n",
    "        if \"unstructured.documents.html.HTMLTable\" in str(type(element)):\n",
    "            should_keep = all([tf(element) for tf in table_filters])\n",
    "            if should_keep:\n",
    "                table_df = html_to_df(str(element.metadata.text_as_html))\n",
    "                output_els.append(\n",
    "                    Element(\n",
    "                        id=f\"id_{idx}\", type=\"table\", element=element, table=table_df\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            output_els.append(Element(id=f\"id_{idx}\", type=\"text\", element=element))\n",
    "    return output_els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_elements(elements):\n",
    "    return [e for e in elements if e.type == \"table\"]\n",
    "\n",
    "\n",
    "def get_text_elements(elements):\n",
    "    return [e for e in elements if e.type == \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = extract_elements(\"tesla_2021_10k.htm\", table_filters=[filter_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split table and text elements\n",
    "table_elements = get_table_elements(elements)\n",
    "text_elements = get_text_elements(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Could not load OpenAIEmbedding. Using HuggingFaceBgeEmbeddings with model_name=BAAI/bge-small-en. If you intended to use OpenAI, please check your OPENAI_API_KEY.\n",
      "Original error:\n",
      "No API key found for OpenAI.\n",
      "Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\n",
      "API keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "## Summarize tables\n",
    "from llama_index import SummaryIndex, Document, ServiceContext\n",
    "from llama_index.llms import Anyscale\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Using anyscale for pricing\n",
    "ANYSCALE_API_KEY = os.environ[\"ANYSCALE_API_KEY\"]\n",
    "llm = Anyscale(\"meta-llama/Llama-2-70b-chat-hf\", api_key=ANYSCALE_API_KEY)\n",
    "\n",
    "system_prompt = \"\"\"\\\n",
    "You are an assistant designed to extract insights from messy tables in a financial report.\n",
    "\n",
    "You are also designed to filter out \"tables\" that are not useful to keep. For instance, if the table \\\n",
    "is a wrongfully extracted piece of text, or does not contain any useful information.\n",
    "\"\"\"\n",
    "service_context = ServiceContext.from_defaults(system_prompt=system_prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script requires that you output the table summaries in a structured format. For this, you'll use `.as_query_engine's` `output_cls` argument.\n",
    "\n",
    "The `output_cls` argument behaves differently depending on the LLM in the service context:\n",
    "- `OpenAI`: Leverages function calling to output the table summaries in a structured format.\n",
    "- `Others`: Parses JSON output as Pydantic Object.\n",
    "\n",
    "In this tutorial, we're using Anyscale. Consequently, we must tell the LLM to output it's results as JSON for `output_cls` to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Could not load OpenAIEmbedding. Using HuggingFaceBgeEmbeddings with model_name=BAAI/bge-small-en. If you intended to use OpenAI, please check your OPENAI_API_KEY.\n",
      "Original error:\n",
      "No API key found for OpenAI.\n",
      "Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\n",
      "API keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "class TableOutput(BaseModel):\n",
    "    summary: str\n",
    "    should_keep: bool\n",
    "\n",
    "\n",
    "summarizer_service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "# TODO: Make these calls asyncronous\n",
    "def extract_table_summaries(elements: list[Element]) -> None:\n",
    "    for element in tqdm(elements):\n",
    "        if element.type != \"table\":\n",
    "            continue\n",
    "        index = SummaryIndex.from_documents([Document(text=str(element.element))], service_context=summarizer_service_context)\n",
    "        query_engine = index.as_query_engine(output_cls=TableOutput)\n",
    "        query_str = \"\"\"\\\n",
    "What is this table about? Give a very concise summary (imagine you are adding a caption), \\\n",
    "and also output whether or not the table should be kept. Return a json object.\n",
    "\"\"\"\n",
    "        response = query_engine.query(query_str)\n",
    "        element.summary = response.response.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3949edecae424ba1bb3b45616abea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract_table_summaries(table_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import pickle\n",
    "pickle.dump(elements, open(\"elements.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode, IndexNode\n",
    "from llama_index.node_parser import SimpleNodeParser, NodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_nodes_from_buffer(buffer, node_parser: NodeParser):\n",
    "    doc = Document(text=\"\\n\\n\".join([t for t in buffer]))\n",
    "    nodes = node_parser.get_nodes_from_documents([doc])\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def get_nodes_and_mappings(elements: list[Element]):\n",
    "    node_parser = SimpleNodeParser.from_defaults()\n",
    "\n",
    "    nodes = []\n",
    "    node_mappings = {}\n",
    "    other_mappings = {}\n",
    "    cur_text_el_buffer = []\n",
    "    for element in elements:\n",
    "        if element.type == \"table\":\n",
    "            if len(cur_text_el_buffer) > 0:\n",
    "                cur_text_nodes = _get_nodes_from_buffer(cur_text_el_buffer, node_parser)\n",
    "                nodes.extend(cur_text_nodes)\n",
    "                cur_text_el_buffer = []\n",
    "\n",
    "            index_node = IndexNode(\n",
    "                text=str(element.summary), index_id=(element.id + \"_table\")\n",
    "            )\n",
    "            table_df = element.table\n",
    "            table_str = table_df.to_string()\n",
    "            node_mappings[(element.id + \"_table\")] = TextNode(text=table_str)\n",
    "            other_mappings[(element.id + \"_table\")] = (\n",
    "                element.table,\n",
    "                str(element.summary),\n",
    "            )\n",
    "            nodes.append(index_node)\n",
    "        else:\n",
    "            cur_text_el_buffer.append(str(element.element))\n",
    "    if len(cur_text_el_buffer) > 0:\n",
    "        cur_text_nodes = _get_nodes_from_buffer(cur_text_el_buffer, node_parser)\n",
    "        nodes.extend(cur_text_nodes)\n",
    "        cur_text_el_buffer = []\n",
    "    return nodes, node_mappings, other_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, node_mappings, other_mappings = get_nodes_and_mappings(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import RecursiveRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct top-level vector index + query engine\n",
    "vector_index = VectorStoreIndex(nodes, service_context=summarizer_service_context)\n",
    "vector_retriever = vector_index.as_retriever(similarity_top_k=1)\n",
    "vector_query_engine = vector_index.as_query_engine(similarity_top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import RecursiveRetriever\n",
    "\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever},\n",
    "    node_dict=node_mappings,\n",
    "    verbose=True,\n",
    ")\n",
    "query_engine = RetrieverQueryEngine.from_args(recursive_retriever, service_context=summarizer_service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mRetrieving with query id None: What were the total cash flows in 2021?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: Cash Flows from Operating Activities\n",
      "\n",
      "Our cash flows from operating activities are significantly affected by our cash investments to support the growth of our business in areas such as research and development and selling, general and administrative and working capital. Our operating cash inflows include cash from vehicle sales and related servicing, customer lease payments, customer deposits, cash from sales of regulatory credits and energy generation and storage products. These cash inflows are offset by our payments to suppliers for production materials and parts used in our manufacturing process, operating expenses, operating lease payments and interest payments on our financings.\n",
      "\n",
      "Net cash provided by operating activities increased by $5.55 billion to $11.50 billion during the year ended December 31, 2021 from $5.94 billion during the year ended December 31, 2020. This increase was primarily due to the increase in net income excluding non-cash expenses and gains of $5.22 billion and the overall decrease in net operating assets and liabilities of $334 million. The decrease in our net operating assets and liabilities was mainly driven by a larger increase of accounts payable and accrued liabilities in the year ended December 31, 2021 as compared to the prior year from ramp up in production at Gigafactory Shanghai and the Fremont Factory. The decrease in our net operating assets and liabilities was partially offset by larger increases of inventory and operating lease vehicles compared to the prior year.\n",
      "\n",
      "Cash Flows from Investing Activities\n",
      "\n",
      "Cash flows from investing activities and their variability across each period related primarily to capital expenditures, which were $6.48 billion for the year ended December 31, 2021 and $3.16 billion for the year ended December 31, 2020, mainly for the construction of Gigafactory Texas and Gigafactory Berlin and the expansions of Gigafactory Shanghai and the Fremont Factory. Additionally, net cash outflows related to digital assets were $1.23 billion in the year ended December 31, 2021 from purchases of digital assets for $1.50 billion offset by proceeds from sales of digital assets of $272 million.\n",
      "\n",
      "Cash Flows from Financing Activities\n",
      "\n",
      "Cash outflows from financing activities were $5.20 billion during the year ended December 31, 2021 compared to $9.97 billion net cash provided by financing activities during the year ended December 31, 2020. The change was primarily due to no equity offerings in 2021 compared to $12.27 billion of proceeds from issuances of common stock net of issuance costs in 2020, a $3.37 billion increase in net repayments of convertible and other debt compared to the prior year, offset by an increase in proceeds from exercise of stock options and other stock issuances of $290 million and a decrease in collateralized lease repayments of $231 million compared to the prior year. See Note 11, Debt, to the consolidated financial statements included elsewhere in this Annual Report on Form 10-K for further details regarding our debt obligations.\n",
      "\n",
      "Recent Accounting Pronouncements\n",
      "\n",
      "See Note 2, Summary of Significant Accounting Policies, to the consolidated financial statements included elsewhere in this Annual Report on Form 10-K.\n",
      "\n",
      "ITEM 7A.\tQUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK\n",
      "\n",
      "Foreign Currency Risk\n",
      "\n",
      "We transact business globally in multiple currencies and hence have foreign currency risks related to our revenue, costs of revenue, operating expenses and localized subsidiary debt denominated in currencies other than the U.S. dollar (primarily the Chinese yuan, euro, Canadian dollar and Norwegian krone in relation to our current year operations). In general, we are a net receiver of currencies other than the U.S. dollar for our foreign subsidiaries. Accordingly, changes in exchange rates affect our revenue and other operating results as expressed in U.S. dollars as we do not typically hedge foreign currency risk.\n",
      "\n",
      "We have also experienced, and will continue to experience, fluctuations in our net income as a result of gains (losses) on the settlement and the re-measurement of monetary assets and liabilities denominated in currencies that are not the local currency (primarily consisting of our intercompany and cash and cash equivalents balances).\n",
      "\n",
      "43\n",
      "\n",
      "We considered the historical trends in foreign currency exchange rates and determined that it is reasonably possible that adverse changes in foreign currency exchange rates of 10% for all currencies could be experienced in the near-term. These changes were applied to our total monetary assets and liabilities denominated in currencies other than our local currencies at the balance sheet date to compute the impact these changes would have had on our net income before income taxes. These changes would have resulted in a gain or loss of $277 million at December 31, 2021 and $8 million at December 31, 2020 assuming no foreign currency hedging.\n",
      "\n",
      "Interest Rate Risk\n",
      "\n",
      "We are exposed to interest rate risk on our borrowings that bear interest at floating rates.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What were the total cash flows in 2021?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Based on the information provided in the context, the total cash flows in 2021 were $11.50 billion, which is the net cash provided by operating activities. This amount represents the cash generated from the company's operations, including cash from vehicle sales and related servicing, customer lease payments, customer deposits, cash from sales of regulatory credits and energy generation and storage products, and offset by payments to suppliers for production materials and parts used in the manufacturing process, operating expenses, operating lease payments, and interest payments on financings.\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
